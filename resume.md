---
layout: single
author: Enrique Reid
permalink: /resume/
title: Resume/CV
toc: true
toc_label: "Resume/CV"
toc_sticky: true
---
[PDF Version](/resources/enriqueareid_resume.pdf)
## 
### Researcher - Matsuo Lab, The University of Tokyo
***November 2020 - Present***

### Visiting Student Researcher, Carnegie Mellon University
***May 2021 - Present***  
Research internship at the Language Technologies Institute, Carnegie Mellon University. Advised by Graham Neubig.

### Research Intern - Matsuo Lab, The University of Tokyo
***October 2019 - October 2020***  
Working on NLP (Natural Language Processing) research at Matsuo Lab, University of Tokyo.

Specifically, I have been working on representation learning, using variational inference for learning natural language edit representations and transfer learning methods for better word embeddings for morphologically rich low resource languages.

Youngest member of the lab - 15yrs (at time of internship)
### Research Intern - Numada Lab, IIS, The University of Tokyo
***June 2019 - September 2019***  
Worked on the development of a machine learning based system for accelerated disaster inquiry responses and for ease of access to information in natural disaster situations.

Youngest member of the lab 14yrs - (at time of internship)
### Researcher - Thomson Reuters Foundation
***May 2019 - June 2019***  
Translated TRF's survey regarding social entrepreneurs and conducted research with companies across Japan to be incorporated into the global study. [[Study Website](http://poll2019.trust.org/){:target="_blank"}] 

***September 2018***  
Conducted research about women-only carriages with Tokyoites in Japanese. Article featured on the World Economic Forum, Japan Times, Thomson Reuters. [[Article](https://www.weforum.org/agenda/2018/11/women-in-tokyo-strongly-back-single-sex-transport-amid-security-fears/){:target="_blank"}]

***August 2018 - September 2018***  
Conducted research about 200 women's views on transportation in Tokyo over 5 days for TRF. Afterwards, developed graphs and visual representations of the data for easy consumption. [[Study Website](http://2018transportpoll.trust.org/city/tokyo/){:target="_blank"}]

## Publications
**Machel Reid** and Victor Zhong. <br /> *"LEWIS: Levenshtein Editing for Unsupervised Text Style Transfer"* <br /> **Findings of the 59th Annual Meeting of the Association for Computational Linguistics (ACL Findings 2021)** [[paper](https://arxiv.org/abs/2105.08206){:target="_blank"}]

Edison Marrese-Taylor, **Machel Reid** and Yutaka Matsuo. <br /> *"Variational Inference for Learning Representations of Natural Language Edits"* <br /> **Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-21)** 5th Workshop on Representation Learning for NLP, Non-archival Track, ACL 2020 [[paper](https://arxiv.org/pdf/2004.09143.pdf){:target="_blank"}]

**Machel Reid**, Edison Marrese-Taylor and Yutaka Matsuo. <br /> *"VCDM: Leveraging Variational Bi-encoding and Deep Contextualized Word Representations for Improved Definition Modeling"*. **The 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP 2020). November 2020. Association for Computational Linguistics** [[paper](/resources/reid20vcdm.pdf){:target="_blank"}]

**Machel Reid**, Edison Marrese-Taylor and Yutaka Matsuo. <br /> *"Combining Pretrained High Resource Embeddings and Subword Representations for Low-Resource Languages"*. **AfricaNLP Workshop, ICLR 2020.** [[paper](https://arxiv.org/pdf/2003.04419.pdf){:target="_blank"}][[poster](/resources/africa-nlp.pdf){:target="_blank"}][[blog](/2020/03/02/combining-pretrained-high-resource-embeddings-and-subword-representations-for-low-resource-languages.html)]
## Reviewing
Primary: AfricaNLP 2021 (co-located with EACL)  
Secondary: EMNLP 2020, INLG 2020, EACL 2021, NAACL 2021

## Teaching
- Teaching Assistant for Introduction to Machine Learning (ItML) 2020, The University of Tokyo

## Awards
### Masason Foundation Scholar
***July 2020 - Present***  
Accepted to the [Masason Foundation](https://masason-foundation.org/en/){:target="_blank"}, which supports youth with high aspirations and exceptional talents. Awarded $10,000 research grant for Cross-Lingual NLP.

### Grand Prize Winner - Rakuten Technology Conference Hackathon 2018
***Oct 2018***  
Our team ('No-name') developed a prototype matchmaking app between babysitters and working parents - Supernannies. This was made to combat problems that working women face in Japan today (career or children?). Out of all 10, carefully-reviewed projects, our team was chosen as the winner.

The app was developed in React Native, with [Google] Firebase as backend. Utilized Rakuten's RapidAPI marketplace to easily access and manage several powerful APIs.
[[Article](https://blog.api.rakuten.net/rtc-hackathon-winners/){:target="_blank"}]

### Google TPU Research Cloud Award
Awarded compute grant by Google

### SoTA Award - Matsuo Lab
Awarded for exceptional contribution to the lab.

### Tests
- JLPT N1 - Passed - Dec 2019
- SAT Math II Subject Test - 800/800 - ***age 13***
- SAT US History Subject Test - 770/800 - ***age 13***
- SAT - 1490/1600 - 720 English, 770 Math - Top 1% - ***age 12***

## Volunteer Activites 
* **ICML 2020 Volunteer**
* **ACL 2020 Volunteer**
* **ICLR 2020 Volunteer**
* **Rakuten RapidAPI Champions Program**  
	Worked in the capacity of a technology evangelist (API Champion) at Rakuten RapidAPI.

	Responsibilities included promoting Rakuten RapidAPI by participation in monthly events, (e.g. judging or mentoring at hackathons, etc..) and developing applications. *Judged at the 2019 Junction Tokyo Hackathon (API Track) at age 14* representing the organization. 

## Certificates
- Deep Learning Specialization (deeplearning.ai) [[Certificate](https://www.coursera.org/account/accomplishments/specialization/EPU5RU5BQV78){:target="_blank"}]
- Machine Learning (Stanford University) [[Certificate](https://www.coursera.org/account/accomplishments/certificate/LUYLSAP6BW3T){:target="_blank"}]

## Skills
**Languages**: English (Native), Japanese (Advanced)

**Programming Languages**: Python (Advanced), JavaScript (Intermediate)

**Libraries**: PyTorch, Transformers, Scikit-Learn
