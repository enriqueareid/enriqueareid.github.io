---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: home
author: Machel Reid 
title: Hi There! Name's Machel
description: Researcher at the University of Tokyo working on natural language processing research
---

I'm a 17-year-old researcher at the University of Tokyo, working on NLP Research at [Matsuo Lab](https://weblab.t.u-tokyo.ac.jp/en/){:target="_blank"} advised by [Yutaka Matsuo](http://ymatsuo.com/){:target="_blank"}. I'm also currently a visiting student at Carnegie Mellon University, advised by [Graham Neubig](http://www.phontron.com). I am currently working on ways to increase transferability of pretrained representations to low resource languages, as well as text style transfer , but I am also interested in/working on definitions, translation, and anything to do with deep generative models (like VAEs). I currently collaborate with NeuLab @ CMU, University of Washington's NLP Group, Facebook AI Research, and Yale University.

## News
* Our paper: [LEWIS: Levenshtein Editing for Unsupervised Text Style Transfer](/resources/reid21lewis.pdf){:target="_blank"} was accepted to [ACL-IJCNLP 2021](https://2021.aclweb.org/){:target="_blank"} (Findings) - May 2021

* Our paper: [Variational Inference for Learning Representations of Natural Language Edits](https://arxiv.org/pdf/2004.09143.pdf){:target="_blank"} was accepted to [AAAI 2021](https://aaai.org/Conferences/AAAI-21/){:target="_blank"} - December 2020

* Our paper [VCDM: Leveraging Variational Bi-encoding and Deep Contextualized Word Representations for Improved Definition Modeling](https://www.aclweb.org/anthology/2020.emnlp-main.513.pdf){:target="_blank"} was accepted at [EMNLP 2020](https://2020.emnlp.org/){:target="_blank"}. Its my 1st first-author conference submission, so I'm extremely happy about this! - September 2020

* I'm extremely grateful to be accepted as a 4th Generation Masason Foundation Scholar! - July 2020

* Our paper: [Variational Inference for Learning Representations of Natural Language Edits](https://arxiv.org/pdf/2004.09143.pdf){:target="_blank"} was accepted to the non-archival track of the [5th Workshop of Representation Learning for NLP](https://sites.google.com/view/repl4nlp2020/){:target="_blank"} at [ACL 2020](http://acl2020.org/){:target="_blank"} - May 2020



